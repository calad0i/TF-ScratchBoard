{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='tanh'),\n",
    "  tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRReducer(tf.keras.callbacks.Callback):\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    old_lr = self.model.optimizer.lr.read_value()\n",
    "    new_lr = old_lr * 0.998\n",
    "    #print(\"\\nEpoch: {}. Reducing Learning Rate from {} to {}\".format(epoch, old_lr, new_lr))\n",
    "    self.model.optimizer.lr.assign(new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,batch_size=512, epochs=100,verbose=0,validation_data=(x_test,y_test),callbacks=[LRReducer()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=1, batch_size=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plt.imshow(x_test[i],cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Prediction:\" + np.array2string(np.argmax(model.predict(np.array([x_test[i]])))) + \"  Target:\" + np.array2string(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb=ks.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(x2_train,y2_train),(x2_test,y2_test)=imdb.load_data(num_words=100000)\n",
    "x2_train=ks.preprocessing.sequence.pad_sequences(x2_train,value=0,padding=\"post\",maxlen=256)\n",
    "x2_test=ks.preprocessing.sequence.pad_sequences(x2_test,value=0,padding=\"post\",maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=dict([(a,b+3) for (a,b) in imdb.get_word_index().items()])\n",
    "index[\"<PAD>\"]=0\n",
    "index[\"^\"]=1\n",
    "index[\"<UNK>\"]=2\n",
    "index[\"<UNUSED>\"]=3\n",
    "index_flip=dict([(b,a) for (a,b) in index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(code):\n",
    "    return \" \".join(index_flip.get(x,\"#\") for x in code)\n",
    "def encode(setence):\n",
    "    return np.array([index.get(x,2) for x in setence.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"Z:\\\\log\", histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn2 = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model2 = tf.keras.models.Sequential([\n",
    "    ks.layers.Embedding(100000,16),\n",
    "    ks.layers.GlobalAveragePooling1D(),\n",
    "    ks.layers.Dense(64, activation='selu'),\n",
    "    ks.layers.Dropout(0.2),\n",
    "    ks.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.fit(x2_train, y2_train,batch_size=5000, epochs=100,verbose=0,validation_data=(x2_test,y2_test),callbacks=[LRReducer(),tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.predict(np.array([encode(\"dont waste your time on this\")]))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.predict(np.array([encode(\"thumbs up\")]))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.predict(np.array([encode(\"dont waste your time on this\")]))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.3.0",
   "language": "python",
   "name": "tensorflow2.3.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}